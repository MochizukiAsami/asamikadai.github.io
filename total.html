<html>
<head>
  <meta charset="utf-8">
  <title>邦楽Bot</title>
</head>
<style>

  .center-box {
    width: 600px;
    height: 400px;
    margin-top: 100px;
    margin-left:auto;
    margin-right: auto;
    padding-top:80px;
    font-size: 1.75rem;
    text-align:center;     
    background-color: crimson;
  }
  .large-text {
    font-size: 4.0rem;
    text-align: center;
    background-color: #FF0;
  }
</style>
<body bgcolor="#FFDBC9">
   
    <p class="center-box">
        吾輩は猫である。<br>
  猫になれば世の中どうでも良くなるにゃ～ん
    <br><img id="mic" src="off.png" width="200" height="200">
        <br>猫のモノマネをどうぞ。 
        <br>:ねこ、にゃん、いぬ、男は黙って、etc…
    </p>
  あれ、あなたも猫に…
<div id="result-div" class="large-text"></div>
  
<script>
  const resultDiv = document.querySelector('#result-div');
  const micDiv = document.querySelector('#mic');
  let speakingtime = 0;
  
  // 音声認識機能(Chrome)
  let rec = new webkitSpeechRecognition();
  let stopped = true;
  rec.continuous = true;
  rec.interimResults = false;
  rec.lang = 'ja-JP';

  micDiv.onclick = function () {
    if (stopped == true) {
      stopped = false;
      resultDiv.innerHTML = "";
      rec.start();
    } else {
      stopped = true;
      rec.stop();
    }
  }

  rec.onstart = function () { 
    console.log('on start');
    micDiv.setAttribute("src","on.png");
    speakingtime = 0;
  };

  rec.onend = function () { 
    console.log('on end');
    micDiv.setAttribute("src","off.png");
    if (stopped == false) {
      setTimeout(function () {
        rec.start();
      },speakingtime);
    }
  };

  rec.onresult = function (e) {
    rec.stop();
    for (let i = e.resultIndex; i < e.results.length; i++) {
      if (e.results[i].isFinal) {
        console.log(e);
        let text = e.results[i][0].transcript;

        console.log(text);
        speakingtime = text.length * 100;
        console.log("estimate:", speakingtime, "ms");
        speak(reply(text));
        resultDiv.innerHTML = text;
      }
    }
  }

  function reply(text){
      
      let re =new RegExp(".*ねこ.*");//これで「キュウソ」という文字があれば、認識される。
      let re1=new RegExp(".*チュール.*");
      let re2=new RegExp(".*男は黙って.*");
      let re3=new RegExp(".*犬.*");
      let re4=new RegExp(".*ペット.*");
      let re5=new RegExp(".*にゃん.*");
      let re6=new RegExp(".*吾輩は.*");
      if(re.test(text)){
          return "にゃー";
          
      }else{
        if(re1.test(text)){
          return "にゃんにゃん";
            
      }else{
        if(re2.test(text)){
          return "鍛高譚";      
      }else{
        if(re3.test(text)){
          return "戦争だ";  
    　}else{
        if(re4.test(text)){
          return "にゃーん";  
      }else{
        if(re5.test(text)){
          return "ニャー"; 
    }else{
        if(re6.test(text)){
          return "猫である"; 
        
        }else{
            return "猫なのでわかりません"; 
          
      }
      
  }
  }
  }
  }
  }
  }
  }
  // 発話機能をインスタンス化
  let msg = new SpeechSynthesisUtterance();
  let voices = window.speechSynthesis.getVoices();

  function speak(text) {
    // 以下オプション設定（日本語は効かないもよう。。）
    msg.voice = voices[7]; // 7:Google 日本人 ja-JP ※他は英語のみ
    msg.volume = 1.0; // 音量 min 0 ~ max 1
    msg.rate = 1.0; // 速度 min 0 ~ max 10
    msg.pitch = 1.0; // 音程 min 0 ~ max 2

    msg.text = text; // 喋る内容
    msg.lang = 'ja-JP'; // en-US or ja-JP
    // msg.lang = 'en-US'; // en-US or ja-JP

    // 発話実行
    speechSynthesis.speak(msg);
  }
  
  // 終了時の処理
  msg.onend = function (event) {
    console.log('喋った時間：' + event.elapsedTime + 'ms');
  }
</script>
    
    <script src="https://cdn.jsdelivr.net/npm/p5"></script>
<script src="https://unpkg.com/ml5@0.4.3/dist/ml5.min.js"></script>

<!-- 2.以下にsetup関数とdraw関数を定義 -->
<script>
let video;
let poseNet;
let poses = [];
let skeletons = [];

    
function preload(){
    neko =loadImage("img/neko.png");
    
}    
    
    
function setup() {
  createCanvas(600, 600);
  video = createCapture(VIDEO);

  // Create a new poseNet method with a single detection
  poseNet = ml5.poseNet(video, modelReady);
  // This sets up an event that fills the global variable "poses"
  // with an array every time new poses are detected
  poseNet.on('pose', function (results) {
    poses = results;
  });
  // Hide the video element, and just show the canvas
  video.hide();
}

function modelReady() {
  select('#status').html('Model Loaded');
}

function draw() {
  image(video, 0, 0, width, height);

  // We can call both functions to draw all keypoints and the skeletons
  drawKeypoints();

}

// A function to draw ellipses over the detected keypoints
function drawKeypoints()  {
  // Loop through all the poses detected
  for (let i = 0; i < poses.length; i++) {
    // For each pose detected, loop through all the keypoints
    for (let j = 0; j < poses[i].pose.keypoints.length; j++) {
      // A keypoint is an object describing a body part (like rightArm or leftShoulder)
      let keypoint = poses[i].pose.keypoints[1];
      // Only draw 0an ellipse is the pose probability is bigger than 0.2
      if (keypoint.score > 0.1) {
        fill(255, 0, 0);
        noStroke();
        image(neko,keypoint.position.x-400,keypoint.position.y-200,600,600);
        //nose(keypoint.position.x, keypoint.position.y, 50, 50);
        fill(10,10,10);
      }
    }
  }
}

// A function to draw the skeletons

  
</script>
</body>
</html>